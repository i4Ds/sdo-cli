{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - Anomaly Analysis run-fhnw-full-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"run-fhnw-full-baseline\"\n",
    "model_config_file = \"/home/marius/sdo-cli/config/threshold/run-fhnw-full-1-predict.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $model_config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sdo-cli sood threshold predict --config-file=\"/home/marius/sdo-cli/config/threshold/run-fhnw-full-1-predict.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred_path = \"/home/marius/sdo-cli/output/threshold/predictions/20220812-095307_cevae/predictions.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sample_pred_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['score'], ascending=False)\n",
    "df[\"score_norm\"] = (df[\"score\"]-df[\"score\"].min())/(df[\"score\"].max()-df[\"score\"].min())\n",
    "df['score_e'] = np.exp(df['score'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"].hist(bins=50, figsize=(14, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_time_format = \"%Y%m%d-%H%M%S\"\n",
    "df[\"t_obs\"] = pd.to_datetime(df[\"t_obs\"])\n",
    "#somehow some images in 2019 are duplicates?\n",
    "df = df.drop_duplicates(subset=['t_obs'], keep='first')\n",
    "df = df.set_index('t_obs', drop=False, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"t_obs\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"t_obs\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h = df.resample(\"1h\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h.index.name = \"timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "ddf = dd.read_parquet(\"/mnt/nas05/astrodata01/astroml_data/goes/goes_ts.parquet\", engine=\"pyarrow\", calculate_divisions=True)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf[(ddf[\"quality_xrsb\"] == 0) & (ddf[\"quality_xrsa\"] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_ts = ddf[\"2011-01-01 00:00\":\"2020-12-30 23:59:59\"].resample(\"1h\").max().compute()\n",
    "goes_ts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_ts[\"xrsb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_goes_and_anomaly_score(df, anomaly_df):\n",
    "    axes = df.plot(title=f\"GOES X-Ray Flux and Normalized Anomaly Score ({experiment_name})\", xlabel=\"Timestamp\", ylabel=\"Watts $m^{-2}$\", logy=True, ylim=(1e-9, 1e-2), figsize=(15, 7.5))\n",
    "    ax2 = axes.twinx()\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.set_ylim(1e-9, 1e-2)\n",
    "    ax2.set_yticklabels([])\n",
    "    axes.yaxis.grid(True, \"major\")\n",
    "    axes.xaxis.grid(False, \"major\")\n",
    "    \n",
    "    ax3 = anomaly_df[[\"score_norm\"]].plot(ax=axes, logy=False, secondary_y=True, color=\"r\")\n",
    "    ax3.set_ylim(0, 1)\n",
    "    #ax3.set_ylabel(\"Normalized Anomaly Score\")\n",
    "    \n",
    "    h1, l1 = axes.get_legend_handles_labels()\n",
    "    plt.legend(h1, l1, loc=2)\n",
    "    \n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_test_years(df):\n",
    "    mask = (((df.index >= \"2011-01-01 00:00\") & (df.index <= \"2011-12-30 23:59:59\"))\n",
    "        | ((df.index >= \"2014-01-01 00:00\") & (df.index <= \"2014-12-30 23:59:59\"))\n",
    "        | ((df.index >= \"2016-01-01 00:00\") & (df.index <= \"2016-12-30 23:59:59\"))\n",
    "        | ((df.index >= \"2019-01-01 00:00\") & (df.index <= \"2019-12-30 23:59:59\")))\n",
    "    \n",
    "    return df.loc[mask]\n",
    "\n",
    "def only_2011(df):\n",
    "    mask = (((df.index >= \"2011-01-01 00:00\") & (df.index <= \"2011-12-30 23:59:59\")))\n",
    "    \n",
    "    return df.loc[mask]\n",
    "\n",
    "def only_2014(df):\n",
    "    mask = (((df.index >= \"2014-01-01 00:00\") & (df.index <= \"2014-12-30 23:59:59\")))\n",
    "    \n",
    "    return df.loc[mask]\n",
    "\n",
    "def only_2016(df):\n",
    "    mask = (((df.index >= \"2016-01-01 00:00\") & (df.index <= \"2016-12-30 23:59:59\")))\n",
    "    \n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def only_2019(df):\n",
    "    mask = (((df.index >= \"2019-01-01 00:00\") & (df.index <= \"2019-12-30 23:59:59\")))\n",
    "    \n",
    "    return df.loc[mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_goes_and_anomaly_score(only_2011(goes_ts)[\"xrsb\"], only_2011(df_1h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_goes_and_anomaly_score(only_2014(goes_ts)[\"xrsb\"], only_2014(df_1h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_goes_and_anomaly_score(only_2016(goes_ts)[\"xrsb\"], only_2016(df_1h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_goes_and_anomaly_score(only_2019(goes_ts)[\"xrsb\"], only_2019(df_1h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_goes_and_anomaly_score(goes_ts[\"xrsb\"], df_1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h.index = df_1h.index.tz_convert(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv(\"/home/marius/sdo-cli/notebooks/pixel_stats_171A_1d.csv\")\n",
    "stats_df[\"timestamp\"] =  pd.to_datetime(stats_df[\"timestamp\"], utc=True)\n",
    "stats_df[\"timestamp\"] = stats_df[\"timestamp\"].apply(\n",
    "            lambda x: x.replace(microsecond=0))\n",
    "stats_df = stats_df.set_index('timestamp', drop=True)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing Anomaly Scores to Pixel intensities\n",
    "\n",
    "def plot_scores_and_pixel_intensities(pixel_df, anomaly_df):\n",
    "    axes = anomaly_df[\"score_norm\"].plot(title=f\"Mean Pixel Intensity AIA 171Å and Normalized Anomaly Score  ({experiment_name})\", xlabel=\"Timestamp\", ylabel=\"Anomaly Score\", color=\"r\", figsize=(15, 7.5))\n",
    "    ax2 = axes.twinx()\n",
    "    ax2.set_yticklabels([])\n",
    "    axes.yaxis.grid(True, \"major\")\n",
    "    axes.xaxis.grid(False, \"major\")\n",
    "    \n",
    "    ax3 = pixel_df.plot(ax=axes, secondary_y=True, color=\"tab:blue\")\n",
    "    ax3.set_ylabel(\"Mean Pixel Intensity\")\n",
    "    \n",
    "    h1, l1 = axes.get_legend_handles_labels()\n",
    "    plt.legend(h1, l1, loc=2)\n",
    "    \n",
    "    return axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores_and_pixel_intensities(stats_df[[\"mean_pixel\"]], df_1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# try to compute the correlation\n",
    "# look at just one year to really see the correlation\n",
    "# find the parts where the two values do not match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_obs_times = []\n",
    "\n",
    "for index, row in df[:1000].iterrows():\n",
    "    t_obs = row[\"t_obs\"] # .isoformat(timespec='milliseconds').replace(\"+00:00\", \"Z\") #.replace(microsecond=0)\n",
    "    top_obs_times.append(t_obs)\n",
    "    \n",
    "top_obs_times[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spaced_obs_times(df, min_diff_seconds=24*60*60, min_size = 100):\n",
    "    obs_times = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        t_obs = row[\"t_obs\"]\n",
    "        has_close_neighbour = False\n",
    "        for obs_time in obs_times:\n",
    "            diff = abs((t_obs - obs_time).total_seconds())\n",
    "            if diff < min_diff_seconds:\n",
    "                has_close_neighbour = True\n",
    "                #print(f\"ignoring {t_obs} for diff {diff}\")\n",
    "                break\n",
    "                \n",
    "            \n",
    "        if not has_close_neighbour:\n",
    "            score = row[\"score_norm\"]\n",
    "            #print(f\"found obs time {t_obs} with score {score}\")\n",
    "            obs_times.append(t_obs)\n",
    "            \n",
    "        if len(obs_times) >= min_size:\n",
    "            break\n",
    "\n",
    "    return obs_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_top_obs_times_1d = spaced_obs_times(df)\n",
    "spaced_top_obs_times_7d = spaced_obs_times(df, min_diff_seconds=24*60*60*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os \n",
    "import sunpy\n",
    "from sunpy.visualization.colormaps import cm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "#inspect an image\n",
    "\n",
    "#Channels that correspond to HMI Magnetograms \n",
    "HMI_WL = ['Bx','By','Bz']\n",
    "#A colormap for visualizing HMI\n",
    "HMI_CM = LinearSegmentedColormap.from_list(\"bwrblack\", [\"#0000ff\",\"#000000\",\"#ff0000\"])\n",
    "\n",
    "def channel_to_map(name):\n",
    "    \"\"\"Given channel name, return colormap\"\"\"\n",
    "    return HMI_CM if name in HMI_WL else cm.cmlist.get('sdoaia%d' % int(name))\n",
    "\n",
    "def vis(X, cm):\n",
    "    \"\"\"Given image, colormap, and visualize results\"\"\"\n",
    "    Xcv = cm(X)\n",
    "    return (Xcv[:,:,:3]*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdo.sood.data.sdo_ml_v2_dataset import get_default_transforms, SDOMLv2NumpyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def get_data_loader(obs_times):\n",
    "    storage_root = \"/home/marius/data/sdomlv2_full/sdomlv2.zarr\"\n",
    "    storage_driver = \"fs\"\n",
    "    cache_max_size = 1*1024*1024*2014\n",
    "    test_year = [\"2011\", \"2014\", \"2016\", \"2019\"]\n",
    "    channel= \"171A\"\n",
    "    target_size = 256\n",
    "    mask_limb = False\n",
    "    mask_limb_radius_scale_factor = 1.0\n",
    "    transforms = get_default_transforms(\n",
    "                target_size=target_size, channel=channel, mask_limb=mask_limb, radius_scale_factor=mask_limb_radius_scale_factor)\n",
    "    dataset = SDOMLv2NumpyDataset(\n",
    "                storage_root=storage_root,\n",
    "                storage_driver=storage_driver,\n",
    "                cache_max_size=cache_max_size,\n",
    "                year=test_year,\n",
    "                start=None,\n",
    "                end=None,\n",
    "                freq=None,\n",
    "                obs_times=obs_times[:10],\n",
    "                irradiance=None,\n",
    "                irradiance_channel=None,\n",
    "                goes_cache_dir=None,\n",
    "                channel=channel,\n",
    "                transforms=transforms,\n",
    "                reduce_memory=True\n",
    "            )\n",
    "    \n",
    "    print(f\"found dataset with size {len(dataset)}\")\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=False,\n",
    "                          drop_last=False,\n",
    "                          prefetch_factor=2)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sunpy.visualization.colormaps import cm\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_grid(imgs, ordered_dates, df, ncols=4, channel=\"171\"):\n",
    "    nrows=int(len(imgs)/ncols)\n",
    "    if nrows <= 0:\n",
    "        nrows = 1\n",
    "        ncols = len(imgs)\n",
    "    fix, axs = plt.subplots(figsize=(20,9), ncols=ncols, nrows=nrows, squeeze=True)\n",
    "    row_index = 0\n",
    "    i = 0\n",
    "    for t_obs in ordered_dates[:10]:\n",
    "        t_obs = t_obs.isoformat(timespec='milliseconds').replace(\"0+00:00\", \"Z\")\n",
    "        img = imgs[t_obs]\n",
    "        row = df.loc[t_obs]\n",
    "        col = i % ncols\n",
    "        if i != 0 and i % ncols == 0:\n",
    "            row_index = row_index + 1\n",
    "        axs[row_index, col].imshow(img)\n",
    "        img_name = f\"{t_obs} {channel}A\"\n",
    "        score = row[\"score_norm\"]\n",
    "        axs[row_index, col].set_title(f\"{img_name}\\n with score \" + \"%.5f\" % score)\n",
    "        axs[row_index, col].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        i += 1\n",
    "    plt.show()\n",
    "\n",
    "def visualize_batch(loader, ordered_dates, img_df):\n",
    "    for batch_idx, samples in enumerate(loader):\n",
    "        X, y = samples\n",
    "        V = {}\n",
    "        for x, t_obs in zip(X, y[\"T_OBS\"]):\n",
    "            x = x.permute(1,2,0) # torch to pillow\n",
    "            x = np.squeeze(x.numpy())\n",
    "            v = vis(x, channel_to_map(171))\n",
    "            V[t_obs] = Image.fromarray(v)\n",
    "        \n",
    "        show_grid(V, ordered_dates, df, ncols=5)\n",
    "        break   \n",
    "        \n",
    "        \n",
    "def visualize_batch_norm(loader, ordered_times, df):\n",
    "    for batch_idx, samples in enumerate(loader):\n",
    "        X, y = samples\n",
    "        V = {}\n",
    "        for x, t_obs in zip(X, y[\"T_OBS\"]):\n",
    "            grid = make_grid(x, normalize=True, value_range=(-1.0, 1.0))\n",
    "            ndarr = grid.mul(255).add_(0.5).clamp_(0, 255).permute(\n",
    "                    1, 2, 0).to(\"cpu\", torch.uint8).numpy()\n",
    "            m = cm.cmlist.get('sdoaia%d' % int(171))\n",
    "            v = np.squeeze(ndarr[:, :, 0])\n",
    "            v = m(v)\n",
    "            v = (v[:, :, :3]*255).astype(np.uint8)\n",
    "            V[t_obs] = Image.fromarray(v)\n",
    "        show_grid(V, ordered_times, df, ncols=5)\n",
    "        break  \n",
    "        \n",
    "def anomaly_threshold(loader, ordered_times, df):\n",
    "    for batch_idx, samples in enumerate(loader):\n",
    "        X, y = samples\n",
    "        V = {}\n",
    "        for x, t_obs in zip(X, y[\"T_OBS\"]):\n",
    "            grid = make_grid(x, normalize=True)\n",
    "            ndarr = grid.mul(255).add_(0.5).clamp_(0, 255).permute(\n",
    "                        1, 2, 0).to(\"cpu\", torch.uint8).numpy()\n",
    "            lower = ndarr.mean() - 2 * ndarr.std()\n",
    "            upper = ndarr.mean() + 2 * ndarr.std()\n",
    "            print(lower, upper)\n",
    "            \n",
    "            ndarr[ndarr < upper] = 0\n",
    "            #ndarr[ndarr >= upper] = 255\n",
    "            \n",
    "            ndarr = np.invert(ndarr)\n",
    "            m = cm.cmlist.get('sdoaia%d' % int(171))\n",
    "            v = np.squeeze(ndarr[:, :, 0])\n",
    "            v = m(v)\n",
    "            v = (v[:, :, :3]*255).astype(np.uint8)\n",
    "            V[t_obs] = Image.fromarray(ndarr)\n",
    "        show_grid(V, ordered_times, df, ncols=5)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_loader = get_data_loader(top_obs_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(top_loader, top_obs_times, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch_norm(top_loader, top_obs_times, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold(top_loader, top_obs_times, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaced 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_1d_top_loader = get_data_loader(spaced_top_obs_times_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(spaced_1d_top_loader, spaced_top_obs_times_1d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch_norm(spaced_1d_top_loader, spaced_top_obs_times_1d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold(spaced_1d_top_loader, spaced_top_obs_times_1d, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaced 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_7d_top_loader = get_data_loader(spaced_top_obs_times_7d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(spaced_7d_top_loader, spaced_top_obs_times_7d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch_norm(spaced_7d_top_loader, spaced_top_obs_times_7d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold(spaced_7d_top_loader, spaced_top_obs_times_7d, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asc = df.sort_values(by=['score'], ascending=True)\n",
    "df_asc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_obs_times = []\n",
    "\n",
    "for index, row in df_asc.head(100).iterrows():\n",
    "    t_obs = row[\"t_obs\"]\n",
    "    bottom_obs_times.append(t_obs)\n",
    "    \n",
    "bottom_obs_times[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_bottom_obs_times_1d = spaced_obs_times(df_asc)\n",
    "spaced_bottom_obs_times_7d = spaced_obs_times(df_asc, min_diff_seconds=24*60*60*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_loader = get_data_loader(bottom_obs_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(bottom_loader, bottom_obs_times, df_asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch_norm(bottom_loader, bottom_obs_times, df_asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold(bottom_loader, bottom_obs_times, df_asc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaced 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_1d_bottom_loader = get_data_loader(spaced_bottom_obs_times_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(spaced_1d_bottom_loader, spaced_bottom_obs_times_1d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch_norm(spaced_1d_bottom_loader, spaced_bottom_obs_times_1d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold(spaced_1d_bottom_loader, spaced_bottom_obs_times_1d, df_asc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaced 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_7d_bottom_loader = get_data_loader(spaced_bottom_obs_times_7d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(spaced_7d_bottom_loader, spaced_bottom_obs_times_7d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch_norm(spaced_7d_bottom_loader, spaced_bottom_obs_times_7d, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold(spaced_7d_bottom_loader, spaced_bottom_obs_times_7d, df_asc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdo-cli",
   "language": "python",
   "name": "sdo-cli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
