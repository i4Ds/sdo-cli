{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0K-qIgUtxCyt"
   },
   "source": [
    "# End-to-end Solar Out-of-Distribution (SOoD) pipeline\n",
    "\n",
    "This notebook presents an end-to-end training and prediction pipeline for Anomaly Detection with a context-encoding variational autoencoder.\n",
    "\n",
    "The model is based on the following paper: Zimmerer, David, et al. \"Context-encoding variational autoencoder for unsupervised anomaly detection.\" arXiv preprint arXiv:1812.05941 (2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAEDc4tR02TW"
   },
   "source": [
    "## Download Code & Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8455,
     "status": "ok",
     "timestamp": 1650112214494,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "Abt3tAiNxZTg",
    "outputId": "bafb9b09-fe2f-460e-9e38-c0efd8fc636f"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 29172,
     "status": "ok",
     "timestamp": 1650112243582,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "ruR7ze5txbYL",
    "outputId": "23a022bd-e171-4081-bd41-e4efe6bfc128"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmariusgiger\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to your W&B account\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTzlqNkqxCyw"
   },
   "source": [
    "##Â Data Acquisition\n",
    "\n",
    "Make sure to run the setup and install `sdo-cli` first (`make setup` and `make install`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1650103938010,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "NFoPl3eLxCyw"
   },
   "outputs": [],
   "source": [
    "# the dataset is available on the nas under /nas08-data02/astroml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b2WtoySxCyz"
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3773899,
     "status": "ok",
     "timestamp": 1650116203521,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "x-Ew_6FNxCy0",
    "outputId": "a3538d0f-724c-4e0f-cd67-db09efd1a6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 15:02:34,537 sdo.sood.algorithms.ce_vae INFO found config\n",
      "2022-06-14 15:02:34,538 sdo.sood.algorithms.ce_vae INFO {\n",
      "  \"model\": {\n",
      "    \"load_path\": {\n",
      "      \"value\": null,\n",
      "      \"desc\": \"Path to a pretrained model\"\n",
      "    },\n",
      "    \"target_size\": {\n",
      "      \"value\": 256,\n",
      "      \"desc\": \"Target size of the reconstructed output\"\n",
      "    },\n",
      "    \"z_dim\": {\n",
      "      \"value\": 128,\n",
      "      \"desc\": \"Dimension of the latent space\"\n",
      "    },\n",
      "    \"fmap_sizes\": {\n",
      "      \"value\": [\n",
      "        16,\n",
      "        64,\n",
      "        256,\n",
      "        1024\n",
      "      ],\n",
      "      \"desc\": \"Feature map sizes for the CNN\"\n",
      "    },\n",
      "    \"ce_factor\": {\n",
      "      \"value\": 0.5,\n",
      "      \"desc\": \"Amount to which the context-encoder contributes to the model (between 0 only VAE and 1 only CE)\"\n",
      "    }\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"data_dir\": {\n",
      "      \"value\": \"/mnt/nas05/astrodata01/astroml_data/sdomlv2.zarr\",\n",
      "      \"desc\": \"Path to the root directory of the dataset\"\n",
      "    },\n",
      "    \"dataset\": {\n",
      "      \"value\": \"SDOMLDatasetV2\",\n",
      "      \"desc\": \"Which dataset to use (CuratedImageParameterDataset, SDOMLDatasetV1 or SDOMLDatasetV2)\"\n",
      "    },\n",
      "    \"num_data_loader_workers\": {\n",
      "      \"value\": 16,\n",
      "      \"desc\": \"How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\"\n",
      "    },\n",
      "    \"prefetch_factor\": {\n",
      "      \"value\": 8,\n",
      "      \"desc\": \"Number of samples loaded in advance by each worker. 2 means there will be a total of 2 * num_workers samples prefetched across all workers.\"\n",
      "    },\n",
      "    \"batch_size\": {\n",
      "      \"value\": 32,\n",
      "      \"desc\": \"How many samples per batch to load\"\n",
      "    },\n",
      "    \"sdo_ml_v2\": {\n",
      "      \"train_year\": {\n",
      "        \"value\": [\n",
      "          \"2010\",\n",
      "          \"2011\"\n",
      "        ],\n",
      "        \"desc\": \"Allows to prefilter the dataset by year. If None all available years will be used.\"\n",
      "      },\n",
      "      \"train_start_date\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"train_end_date\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"test_year\": {\n",
      "        \"value\": [\n",
      "          \"2012\"\n",
      "        ],\n",
      "        \"desc\": \"Allows to prefilter the dataset by year. If None all available years will be used.\"\n",
      "      },\n",
      "      \"test_start_date\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"test_end_date\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"train_val_split_ratio\": {\n",
      "        \"value\": 0.8,\n",
      "        \"desc\": \"Split-ratio for the train-validation split\"\n",
      "      },\n",
      "      \"train_val_split_temporal_chunk_size\": {\n",
      "        \"value\": \"3d\",\n",
      "        \"desc\": \"Temporal chunk size for the train-validation splits.\"\n",
      "      },\n",
      "      \"storage_driver\": {\n",
      "        \"value\": \"fs\",\n",
      "        \"desc\": \"Storage driver used to load the data. Either 'gcs' (Google Storage Bucket) or 'fs' (local file system)\"\n",
      "      },\n",
      "      \"channel\": {\n",
      "        \"value\": \"171A\",\n",
      "        \"desc\": \"Allows to filter the dataset by channel. If None all available channels will be used.\"\n",
      "      },\n",
      "      \"irradiance\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to filter by irradiance (all images with smaller or equal values will be in the resulting dataset). Defaults to None.\"\n",
      "      },\n",
      "      \"goes_cache_dir\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Path to the cached GOES values (downloaded with sdo-cli goes download --help). Defaults to None.\"\n",
      "      },\n",
      "      \"freq\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to downsample the dataset temporally, should be bigger than the min interval for the observed channel. When using freq, start and end should also be specified for train and test\"\n",
      "      }\n",
      "    },\n",
      "    \"channel\": {\n",
      "      \"value\": \"171A\",\n",
      "      \"desc\": \"Channel name that should be used. If None all available channels will be used.\"\n",
      "    },\n",
      "    \"pin_memory\": {\n",
      "      \"value\": true,\n",
      "      \"desc\": \"If true, the data loader will copy Tensors into CUDA pinned memory before returning them\"\n",
      "    }\n",
      "  },\n",
      "  \"predict\": {\n",
      "    \"mode\": {\n",
      "      \"value\": \"sample\",\n",
      "      \"desc\": \"Mode for anomaly scoring (pixel or sample)\"\n",
      "    },\n",
      "    \"pred_dir\": {\n",
      "      \"value\": \"./output/predictions\",\n",
      "      \"desc\": \"Output directory for predictions.\"\n",
      "    },\n",
      "    \"score_mode\": {\n",
      "      \"value\": \"combi\",\n",
      "      \"desc\": \"Score mode used for anomaly scoring ('rec', 'grad' or 'combi')\"\n",
      "    }\n",
      "  },\n",
      "  \"log_dir\": {\n",
      "    \"value\": \"./output/train-sdo-ml\",\n",
      "    \"desc\": \"Output directory for log.\"\n",
      "  },\n",
      "  \"train\": {\n",
      "    \"n_epochs\": {\n",
      "      \"value\": 10,\n",
      "      \"desc\": \"Stop training once this number of epochs is reached.\"\n",
      "    },\n",
      "    \"lr\": {\n",
      "      \"value\": 0.0001,\n",
      "      \"desc\": \"Learning rate\"\n",
      "    },\n",
      "    \"use_geco\": {\n",
      "      \"value\": false,\n",
      "      \"desc\": \"Whether to use Generalized ELBO with Constrained Optimization update step.\"\n",
      "    },\n",
      "    \"beta\": {\n",
      "      \"value\": 0.01,\n",
      "      \"desc\": \"Weighting factor for KL loss influence on loss.\"\n",
      "    },\n",
      "    \"print_every_iter\": {\n",
      "      \"value\": 100,\n",
      "      \"desc\": \"\"\n",
      "    },\n",
      "    \"profile\": {\n",
      "      \"value\": false,\n",
      "      \"desc\": \"Whether to profile the training run (only for debugging)\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "2022-06-14 15:02:34,595 torch.distributed.nn.jit.instantiator INFO Created a temporary directory at /tmp/tmpot1fxuir\n",
      "2022-06-14 15:02:34,595 torch.distributed.nn.jit.instantiator INFO Writing /tmp/tmpot1fxuir/_remote_module_non_sriptable.py\n",
      "discovered the following zarr directory structure\n",
      "/\n",
      " â”œâ”€â”€ 2010\n",
      " â”‚   â”œâ”€â”€ 131A (47116, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (47972, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (46858, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (47186, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (47134, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (47186, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (47131, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (47187, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (46930, 512, 512) float32\n",
      " â”œâ”€â”€ 2011\n",
      " â”‚   â”œâ”€â”€ 131A (75200, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (75814, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74839, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (75660, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (75664, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (75678, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (74199, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (75624, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (75138, 512, 512) float32\n",
      " â”œâ”€â”€ 2012\n",
      " â”‚   â”œâ”€â”€ 131A (76849, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (76630, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (69091, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (76750, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (76852, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (76870, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (76851, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (76855, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (76878, 512, 512) float32\n",
      " â”œâ”€â”€ 2013\n",
      " â”‚   â”œâ”€â”€ 131A (82719, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (83001, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74989, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (82633, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (82716, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (82746, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (82715, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (82723, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (82746, 512, 512) float32\n",
      " â”œâ”€â”€ 2014\n",
      " â”‚   â”œâ”€â”€ 131A (73605, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (73390, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (66326, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (73487, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (73603, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (73617, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (73602, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (73604, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (73618, 512, 512) float32\n",
      " â”œâ”€â”€ 2015\n",
      " â”‚   â”œâ”€â”€ 131A (82822, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (82859, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74863, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (82806, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (82849, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (82842, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (82845, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (82834, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (82870, 512, 512) float32\n",
      " â”œâ”€â”€ 2016\n",
      " â”‚   â”œâ”€â”€ 131A (82129, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (82117, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74199, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (82136, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (82135, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (82152, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (82123, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (82137, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (82144, 512, 512) float32\n",
      " â”œâ”€â”€ 2017\n",
      " â”‚   â”œâ”€â”€ 131A (85273, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (85306, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (77094, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (85274, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (85277, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (85275, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (85243, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (85276, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (85254, 512, 512) float32\n",
      " â”œâ”€â”€ 2018\n",
      " â”‚   â”œâ”€â”€ 131A (84783, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (84897, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (76723, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (84885, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (84881, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (84896, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (84883, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (84784, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (84899, 512, 512) float32\n",
      " â”œâ”€â”€ 2019\n",
      " â”‚   â”œâ”€â”€ 131A (87236, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (87234, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (78839, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (87235, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (87244, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (87260, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (87238, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (87252, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (87263, 512, 512) float32\n",
      " â””â”€â”€ 2020\n",
      "     â”œâ”€â”€ 131A (85524, 512, 512) float32\n",
      "     â”œâ”€â”€ 1600A (86001, 512, 512) float32\n",
      "     â”œâ”€â”€ 1700A (77725, 512, 512) float32\n",
      "     â”œâ”€â”€ 171A (85985, 512, 512) float32\n",
      "     â”œâ”€â”€ 193A (85561, 512, 512) float32\n",
      "     â”œâ”€â”€ 211A (85581, 512, 512) float32\n",
      "     â”œâ”€â”€ 304A (85982, 512, 512) float32\n",
      "     â”œâ”€â”€ 335A (85529, 512, 512) float32\n",
      "     â””â”€â”€ 94A (85998, 512, 512) float32\n",
      "found 122846 images\n",
      "discovered the following zarr directory structure\n",
      "/\n",
      " â”œâ”€â”€ 2010\n",
      " â”‚   â”œâ”€â”€ 131A (47116, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (47972, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (46858, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (47186, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (47134, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (47186, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (47131, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (47187, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (46930, 512, 512) float32\n",
      " â”œâ”€â”€ 2011\n",
      " â”‚   â”œâ”€â”€ 131A (75200, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (75814, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74839, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (75660, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (75664, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (75678, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (74199, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (75624, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (75138, 512, 512) float32\n",
      " â”œâ”€â”€ 2012\n",
      " â”‚   â”œâ”€â”€ 131A (76849, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (76630, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (69091, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (76750, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (76852, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (76870, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (76851, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (76855, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (76878, 512, 512) float32\n",
      " â”œâ”€â”€ 2013\n",
      " â”‚   â”œâ”€â”€ 131A (82719, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (83001, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74989, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (82633, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (82716, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (82746, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (82715, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (82723, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (82746, 512, 512) float32\n",
      " â”œâ”€â”€ 2014\n",
      " â”‚   â”œâ”€â”€ 131A (73605, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (73390, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (66326, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (73487, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (73603, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (73617, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (73602, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (73604, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (73618, 512, 512) float32\n",
      " â”œâ”€â”€ 2015\n",
      " â”‚   â”œâ”€â”€ 131A (82822, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (82859, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74863, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (82806, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (82849, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (82842, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (82845, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (82834, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (82870, 512, 512) float32\n",
      " â”œâ”€â”€ 2016\n",
      " â”‚   â”œâ”€â”€ 131A (82129, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (82117, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (74199, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (82136, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (82135, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (82152, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (82123, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (82137, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (82144, 512, 512) float32\n",
      " â”œâ”€â”€ 2017\n",
      " â”‚   â”œâ”€â”€ 131A (85273, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (85306, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (77094, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (85274, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (85277, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (85275, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (85243, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (85276, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (85254, 512, 512) float32\n",
      " â”œâ”€â”€ 2018\n",
      " â”‚   â”œâ”€â”€ 131A (84783, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (84897, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (76723, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (84885, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (84881, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (84896, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (84883, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (84784, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (84899, 512, 512) float32\n",
      " â”œâ”€â”€ 2019\n",
      " â”‚   â”œâ”€â”€ 131A (87236, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1600A (87234, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 1700A (78839, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 171A (87235, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 193A (87244, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 211A (87260, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 304A (87238, 512, 512) float32\n",
      " â”‚   â”œâ”€â”€ 335A (87252, 512, 512) float32\n",
      " â”‚   â””â”€â”€ 94A (87263, 512, 512) float32\n",
      " â””â”€â”€ 2020\n",
      "     â”œâ”€â”€ 131A (85524, 512, 512) float32\n",
      "     â”œâ”€â”€ 1600A (86001, 512, 512) float32\n",
      "     â”œâ”€â”€ 1700A (77725, 512, 512) float32\n",
      "     â”œâ”€â”€ 171A (85985, 512, 512) float32\n",
      "     â”œâ”€â”€ 193A (85561, 512, 512) float32\n",
      "     â”œâ”€â”€ 211A (85581, 512, 512) float32\n",
      "     â”œâ”€â”€ 304A (85982, 512, 512) float32\n",
      "     â”œâ”€â”€ 335A (85529, 512, 512) float32\n",
      "     â””â”€â”€ 94A (85998, 512, 512) float32\n",
      "found 76750 images\n",
      "Selecting groups for train-validation split. Number of groups 199, number of groups for training 160, number of groups for validation 39\n",
      "splitting Dataset into two subsets. Train size 98818, validation size 24028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmariusgiger\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/data1/home/marius/sdo-cli/notebooks/wandb/run-20220614_150353-34eoz7ka\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisunderstood-firebrand-95\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mariusgiger/sdo-sood\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/mariusgiger/sdo-sood/runs/34eoz7ka\u001b[0m\n",
      "2022-06-14 15:03:55,836 pytorch_lightning.utilities.rank_zero INFO Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "2022-06-14 15:03:55,838 pytorch_lightning.utilities.rank_zero INFO GPU available: True, used: True\n",
      "2022-06-14 15:03:55,838 pytorch_lightning.utilities.rank_zero INFO TPU available: False, using: 0 TPU cores\n",
      "2022-06-14 15:03:55,839 pytorch_lightning.utilities.rank_zero INFO IPU available: False, using: 0 IPUs\n",
      "2022-06-14 15:03:55,839 pytorch_lightning.utilities.rank_zero INFO HPU available: False, using: 0 HPUs\n",
      "2022-06-14 15:04:10,767 pytorch_lightning.accelerators.gpu INFO LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "2022-06-14 15:04:10,786 pytorch_lightning.callbacks.model_summary INFO \n",
      "   | Name                       | Type            | Params\n",
      "----------------------------------------------------------------\n",
      "0  | model                      | VAE             | 107 M \n",
      "1  | model.enc                  | BasicEncoder    | 69.6 M\n",
      "2  | model.enc.start            | ConvModule      | 144   \n",
      "3  | model.enc.start.conv       | Conv2d          | 144   \n",
      "4  | model.enc.start.activation | LeakyReLU       | 0     \n",
      "5  | model.enc.middle_blocks    | ModuleList      | 2.5 M \n",
      "6  | model.enc.middle_blocks.0  | NoOp            | 0     \n",
      "7  | model.enc.middle_blocks.1  | ConvModule      | 9.2 K \n",
      "8  | model.enc.middle_blocks.2  | NoOp            | 0     \n",
      "9  | model.enc.middle_blocks.3  | ConvModule      | 147 K \n",
      "10 | model.enc.middle_blocks.4  | NoOp            | 0     \n",
      "11 | model.enc.middle_blocks.5  | ConvModule      | 2.4 M \n",
      "12 | model.enc.end              | ConvModule      | 67.1 M\n",
      "13 | model.enc.end.conv         | Conv2d          | 67.1 M\n",
      "14 | model.dec                  | BasicGenerator  | 38.0 M\n",
      "15 | model.dec.start            | ConvModule      | 33.6 M\n",
      "16 | model.dec.start.conv       | ConvTranspose2d | 33.6 M\n",
      "17 | model.dec.start.activation | LeakyReLU       | 0     \n",
      "18 | model.dec.middle_blocks    | ModuleList      | 4.5 M \n",
      "19 | model.dec.middle_blocks.0  | NoOp            | 0     \n",
      "20 | model.dec.middle_blocks.1  | ConvModule      | 4.2 M \n",
      "21 | model.dec.middle_blocks.2  | NoOp            | 0     \n",
      "22 | model.dec.middle_blocks.3  | ConvModule      | 262 K \n",
      "23 | model.dec.middle_blocks.4  | NoOp            | 0     \n",
      "24 | model.dec.middle_blocks.5  | ConvModule      | 16.4 K\n",
      "25 | model.dec.end              | ConvModule      | 256   \n",
      "26 | model.dec.end.conv         | ConvTranspose2d | 256   \n",
      "----------------------------------------------------------------\n",
      "107 M     Trainable params\n",
      "0         Non-trainable params\n",
      "107 M     Total params\n",
      "430.610   Total estimated model params size (MB)\n",
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/home/marius/sdo-cli/.venv/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "Epoch 0:   5%|â–      | 200/3840 [01:52<34:08,  1.78it/s, loss=0.145, v_num=z7ka]"
     ]
    }
   ],
   "source": [
    "!../.venv/bin/sdo-cli sood ce_vae train \\\n",
    "    --config-file=\"/home/marius/sdo-cli/config/ce-vae/run-fhnw-1.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpRNpwFgxCy0"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jt5780_BxCy2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 16:24:00,185 sdo.sood.algorithms.ce_vae INFO found config\n",
      "2022-06-15 16:24:00,186 sdo.sood.algorithms.ce_vae INFO {\n",
      "  \"model\": {\n",
      "    \"load_path\": {\n",
      "      \"value\": \"/Users/mariusgiger/Downloads/model.ckpt\",\n",
      "      \"desc\": \"Path to a pretrained model\"\n",
      "    },\n",
      "    \"target_size\": {\n",
      "      \"value\": 256,\n",
      "      \"desc\": \"Target size of the reconstructed output\"\n",
      "    },\n",
      "    \"z_dim\": {\n",
      "      \"value\": 128,\n",
      "      \"desc\": \"Dimension of the latent space\"\n",
      "    },\n",
      "    \"fmap_sizes\": {\n",
      "      \"value\": [\n",
      "        16,\n",
      "        64,\n",
      "        256,\n",
      "        1024\n",
      "      ],\n",
      "      \"desc\": \"Feature map sizes for the CNN\"\n",
      "    },\n",
      "    \"ce_factor\": {\n",
      "      \"value\": 0.5,\n",
      "      \"desc\": \"Amount to which the context-encoder contributes to the model (between 0 only VAE and 1 only CE)\"\n",
      "    }\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"data_dir\": {\n",
      "      \"value\": \"fdl-sdoml-v2/sdomlv2_small.zarr/\",\n",
      "      \"desc\": \"Path to the root directory of the dataset\"\n",
      "    },\n",
      "    \"dataset\": {\n",
      "      \"value\": \"SDOMLDatasetV2\",\n",
      "      \"desc\": \"Which dataset to use (CuratedImageParameterDataset, SDOMLDatasetV1 or SDOMLDatasetV2)\"\n",
      "    },\n",
      "    \"num_data_loader_workers\": {\n",
      "      \"value\": 0,\n",
      "      \"desc\": \"How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\"\n",
      "    },\n",
      "    \"prefetch_factor\": {\n",
      "      \"value\": 2,\n",
      "      \"desc\": \"Number of samples loaded in advance by each worker. 2 means there will be a total of 2 * num_workers samples prefetched across all workers.\"\n",
      "    },\n",
      "    \"batch_size\": {\n",
      "      \"value\": 1,\n",
      "      \"desc\": \"How many samples per batch to load\"\n",
      "    },\n",
      "    \"sdo_ml_v2\": {\n",
      "      \"storage_driver\": {\n",
      "        \"value\": \"gcs\",\n",
      "        \"desc\": \"Storage driver used to load the data. Either 'gcs' (Google Storage Bucket) or 'fs' (local file system)\"\n",
      "      },\n",
      "      \"train_start_date\": {\n",
      "        \"value\": \"2010-08-30 00:00:00\",\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"train_end_date\": {\n",
      "        \"value\": \"2010-08-30 23:59:59\",\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"test_start_date\": {\n",
      "        \"value\": \"2010-08-29 00:00:00\",\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"test_end_date\": {\n",
      "        \"value\": \"2010-08-29 23:59:59\",\n",
      "        \"desc\": \"Allows to restrict the dataset temporally\"\n",
      "      },\n",
      "      \"train_val_split_temporal_chunk_size\": {\n",
      "        \"value\": \"1h\",\n",
      "        \"desc\": \"Temporal chunk size for the train-validation splits.\"\n",
      "      },\n",
      "      \"channel\": {\n",
      "        \"value\": \"171A\",\n",
      "        \"desc\": \"Allows to filter the dataset by channel. If None all available channels will be used.\"\n",
      "      },\n",
      "      \"train_year\": {\n",
      "        \"value\": \"2010\",\n",
      "        \"desc\": \"Allows to prefilter the dataset by year. If None all available years will be used.\"\n",
      "      },\n",
      "      \"test_year\": {\n",
      "        \"value\": \"2010\",\n",
      "        \"desc\": \"Allows to prefilter the dataset by year. If None all available years will be used.\"\n",
      "      },\n",
      "      \"irradiance\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to filter by irradiance (all images with smaller or equal values will be in the resulting dataset). Defaults to None.\"\n",
      "      },\n",
      "      \"goes_cache_dir\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Path to the cached GOES values (downloaded with sdo-cli goes download --help). Defaults to None.\"\n",
      "      },\n",
      "      \"freq\": {\n",
      "        \"value\": null,\n",
      "        \"desc\": \"Allows to downsample the dataset temporally, should be bigger than the min interval for the observed channel. When using freq, start and end should also be specified for train and test\"\n",
      "      },\n",
      "      \"train_val_split_ratio\": {\n",
      "        \"value\": 0.7,\n",
      "        \"desc\": \"Split-ratio for the train-validation split\"\n",
      "      }\n",
      "    },\n",
      "    \"channel\": {\n",
      "      \"value\": \"171A\",\n",
      "      \"desc\": \"Channel name that should be used. If None all available channels will be used.\"\n",
      "    },\n",
      "    \"pin_memory\": {\n",
      "      \"value\": false,\n",
      "      \"desc\": \"If true, the data loader will copy Tensors into CUDA pinned memory before returning them\"\n",
      "    }\n",
      "  },\n",
      "  \"predict\": {\n",
      "    \"mode\": {\n",
      "      \"value\": \"sample\",\n",
      "      \"desc\": \"Mode for anomaly scoring (pixel or sample)\"\n",
      "    },\n",
      "    \"pred_dir\": {\n",
      "      \"value\": \"./output/predictions\",\n",
      "      \"desc\": \"Output directory for predictions.\"\n",
      "    },\n",
      "    \"score_mode\": {\n",
      "      \"value\": \"combi\",\n",
      "      \"desc\": \"Score mode used for anomaly scoring ('rec', 'grad' or 'combi')\"\n",
      "    }\n",
      "  },\n",
      "  \"train\": {\n",
      "    \"n_epochs\": {\n",
      "      \"value\": 10,\n",
      "      \"desc\": \"Stop training once this number of epochs is reached.\"\n",
      "    },\n",
      "    \"lr\": {\n",
      "      \"value\": 0.0001,\n",
      "      \"desc\": \"Learning rate\"\n",
      "    },\n",
      "    \"use_geco\": {\n",
      "      \"value\": false,\n",
      "      \"desc\": \"Whether to use Generalized ELBO with Constrained Optimization update step.\"\n",
      "    },\n",
      "    \"beta\": {\n",
      "      \"value\": 0.01,\n",
      "      \"desc\": \"Weighting factor for KL loss influence on loss.\"\n",
      "    },\n",
      "    \"print_every_iter\": {\n",
      "      \"value\": 100,\n",
      "      \"desc\": \"\"\n",
      "    },\n",
      "    \"profile\": {\n",
      "      \"value\": false,\n",
      "      \"desc\": \"Whether to profile the training run (only for debugging)\"\n",
      "    },\n",
      "    \"early_stopping\": {\n",
      "      \"value\": true,\n",
      "      \"desc\": \"Whether to enable early stopping\"\n",
      "    }\n",
      "  },\n",
      "  \"log_dir\": {\n",
      "    \"value\": \"./output/logs\",\n",
      "    \"desc\": \"Output directory for log.\"\n",
      "  }\n",
      "}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/bin/sdo-cli\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('sdo-cli', 'console_scripts', 'sdo-cli')())\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/decorators.py\", line 84, in new_func\n",
      "    return ctx.invoke(f, obj, *args, **kwargs)\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/src/sdo/cmd/sood/ce_vae/cmd_predict.py\", line 12, in predict\n",
      "    main(\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/src/sdo/sood/algorithms/ce_vae.py\", line 387, in main\n",
      "    cevae_algo = ceVAE.load_from_checkpoint(\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/pytorch_lightning/core/saving.py\", line 161, in load_from_checkpoint\n",
      "    model = cls._load_model_state(checkpoint, strict=strict, **kwargs)\n",
      "  File \"/Users/mariusgiger/repos/master/sdo-cli/.venv/lib/python3.9/site-packages/pytorch_lightning/core/saving.py\", line 203, in _load_model_state\n",
      "    model = cls(**_cls_kwargs)\n",
      "TypeError: __init__() missing 9 required positional arguments: 'input_shape', 'lr', 'z_dim', 'model_feature_map_sizes', 'use_geco', 'beta', 'ce_factor', 'score_mode', and 'print_every_iter'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "# pixel-level predictions\n",
    "\n",
    "!sdo-cli sood ce_vae predict \\\n",
    "    --config-file=\"/Users/mariusgiger/repos/master/sdo-cli/config/ce-vae/run-1.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdo.sood.algorithms.ce_vae import ceVAE\n",
    "\n",
    "load_path = \"/Users/mariusgiger/Downloads/model_cevae_256.ckpt\"\n",
    "mode = \"sample\"\n",
    "cevae_algo = ceVAE.load_from_checkpoint(\n",
    "            load_path, mode=mode)\n",
    "cevae_algo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib \n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, Normalize, Lambda\n",
    "import math\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "CHANNEL_PREPROCESS = {\n",
    "    \"94\": {\"min\": 0.1, \"max\": 800, \"scaling\": \"log10\"},\n",
    "    \"131\": {\"min\": 0.7, \"max\": 1900, \"scaling\": \"log10\"},\n",
    "    \"171\": {\"min\": 5, \"max\": 3500, \"scaling\": \"log10\"},\n",
    "    \"193\": {\"min\": 20, \"max\": 5500, \"scaling\": \"log10\"},\n",
    "    \"211\": {\"min\": 7, \"max\": 3500, \"scaling\": \"log10\"},\n",
    "    \"304\": {\"min\": 0.1, \"max\": 3500, \"scaling\": \"log10\"},\n",
    "    \"335\": {\"min\": 0.4, \"max\": 1000, \"scaling\": \"log10\"},\n",
    "    \"1600\": {\"min\": 10, \"max\": 800, \"scaling\": \"log10\"},\n",
    "    \"1700\": {\"min\": 220, \"max\": 5000, \"scaling\": \"log10\"},\n",
    "    \"4500\": {\"min\": 4000, \"max\": 20000, \"scaling\": \"log10\"},\n",
    "    \"continuum\": {\"min\": 0, \"max\": 65535, \"scaling\": None},\n",
    "    \"magnetogram\": {\"min\": -250, \"max\": 250, \"scaling\": None},\n",
    "    \"bx\": {\"min\": -250, \"max\": 250, \"scaling\": None},\n",
    "    \"by\": {\"min\": -250, \"max\": 250, \"scaling\": None},\n",
    "    \"bz\": {\"min\": -250, \"max\": 250, \"scaling\": None},\n",
    "}\n",
    "\n",
    "predict_img_path = pathlib.Path(\"/Users/mariusgiger/repos/master/test-sdo-ml-dataset-ae/extract/train/2012/01/01/AIA20120101_0000_0171.npz\")\n",
    "\n",
    "np_arr = np.load(predict_img_path)[\"x\"]  # .astype(np.float64)\n",
    "torch_arr = torch.from_numpy(np_arr)\n",
    "# convert to 1 x H x W, to be in compatible torchvision format\n",
    "torch_arr = torch_arr.unsqueeze(dim=0)\n",
    "\n",
    "channel = \"171\"\n",
    "preprocess_config = CHANNEL_PREPROCESS[channel.lower()]\n",
    "\n",
    "target_size = 256\n",
    "if preprocess_config[\"scaling\"] == \"log10\":\n",
    "    # TODO why was vflip(x) used here in SolarNet?\n",
    "    def lambda_transform(x): return torch.log10(torch.clamp(\n",
    "            x,\n",
    "            min=preprocess_config[\"min\"],\n",
    "            max=preprocess_config[\"max\"],\n",
    "    ))\n",
    "    mean = math.log10(preprocess_config[\"min\"])\n",
    "    std = math.log10(preprocess_config[\"max\"]) - \\\n",
    "            math.log10(preprocess_config[\"min\"])\n",
    "else:\n",
    "    def lambda_transform(x): return torch.clamp(\n",
    "            x,\n",
    "            min=preprocess_config[\"min\"],\n",
    "            max=preprocess_config[\"max\"],\n",
    "    )\n",
    "    mean = preprocess_config[\"min\"]\n",
    "    std = preprocess_config[\"max\"] - preprocess_config[\"min\"]\n",
    "\n",
    "transforms = Compose(\n",
    "        [Resize((target_size, target_size)),\n",
    "         Lambda(lambda_transform),\n",
    "         Normalize(mean=[mean], std=[std]),\n",
    "         # required to remove strange distribution of pixels (everything too bright)\n",
    "         Normalize(mean=(0.5), std=(0.5))\n",
    "         ]\n",
    ")\n",
    "torch_arr = transforms(torch_arr)\n",
    "with torch.no_grad():\n",
    "    cevae_algo.sample_mode()\n",
    "    pred = cevae_algo.forward(torch_arr)\n",
    "    print(pred)\n",
    "cevae_algo.pixel_mode()\n",
    "#NOTE this mode requires grad to be enabled\n",
    "pred_img = cevae_algo.forward(torch_arr)\n",
    "save_image(pred_img, \"./output/test.png\", normalize=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Arx8OakexCy2"
   },
   "outputs": [],
   "source": [
    "# display inverted pixel-wise anomaly scores\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "\n",
    "aia_wave = 171\n",
    "newest_dir = find_newest_dir('./output/pred/*/')\n",
    "pixel_pred_path =  newest_dir / Path(\"predictions\")\n",
    "images = list(Path(pixel_pred_path).rglob(f'*__{aia_wave}.jpeg'))\n",
    "\n",
    "f, axarr = plt.subplots(1,7, figsize=(20, 9))\n",
    "\n",
    "row_index = 0\n",
    "column_index = 0\n",
    "\n",
    "for index, path in enumerate(images):\n",
    "    img = Image.open(path)\n",
    "    img_arr = np.invert(np.asarray(img))\n",
    "    axarr[column_index].set_title(path.stem)\n",
    "    axarr[column_index].imshow(img_arr, cmap='gray', vmin=0, vmax=255)\n",
    "    axarr[column_index].spines['top'].set_visible(False)\n",
    "    axarr[column_index].spines['right'].set_visible(False)\n",
    "    axarr[column_index].spines['bottom'].set_visible(False)\n",
    "    axarr[column_index].spines['left'].set_visible(False)\n",
    "    axarr[column_index].xaxis.set_ticks([])\n",
    "    axarr[column_index].yaxis.set_ticks([])\n",
    "\n",
    "    if(column_index == 6):\n",
    "        row_index = (row_index + 1)\n",
    "        \n",
    "    column_index = (column_index + 1) % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmBHKyRHxCy2"
   },
   "outputs": [],
   "source": [
    "# sample-level predictions\n",
    "\n",
    "!sdo-cli sood ce_vae predict \\\n",
    "    --target-size=256 \\\n",
    "    --data-dir='./data/aia_171_2012_256' \\\n",
    "    --test-dir='./data/aia_171_2012_full_disk_flare_256' \\\n",
    "    --load-path={load_path} \\\n",
    "    -o './output/pred' \\\n",
    "    --logger \"file\" \\\n",
    "    --ce-factor 0.5 \\\n",
    "    --score-mode combi \\\n",
    "    --mode=\"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xwna3YWUxCy3"
   },
   "outputs": [],
   "source": [
    "# investigate sample-wise scores\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "newest_dir = find_newest_dir('./output/pred/*/')\n",
    "sample_pred_path =  newest_dir / Path(\"predictions/predictions.txt\")\n",
    "\n",
    "df = pd.read_csv(sample_pred_path, header=None, names = [\"img\", \"score\"])\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUkf7I-hxCy3"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlIqP9G9xCy3"
   },
   "outputs": [],
   "source": [
    "!sdo-cli sood ce_vae generate \\\n",
    "    --target-size=256 \\\n",
    "    --data-dir='./data/aia_171_2012_256' \\\n",
    "    --test-dir='./data/aia_171_2012_full_disk_flare_256' \\\n",
    "    --load-path={load_path} \\\n",
    "    -o './output/' \\\n",
    "    --logger \"file\" \\\n",
    "    --ce-factor 0.5 \\\n",
    "    --score-mode combi \\\n",
    "    --mode=\"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GedYbQ6QxCy3"
   },
   "outputs": [],
   "source": [
    "gen_data_dir = \"./output\"\n",
    "images = list(Path(gen_data_dir).rglob(f'*_generated.jpeg'))\n",
    "img_path = images[0]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "\n",
    "src_img = Image.open(img_path)\n",
    "plt.imshow(np.asarray(src_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFtcPHHIxCy4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of ce-vae__e2e-pipeline-sdo-ml.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/i4Ds/sdo-cli/blob/main/notebooks/ce-vae__e2e-pipeline-sdo-ml.ipynb",
     "timestamp": 1650118558933
    }
   ]
  },
  "kernelspec": {
   "display_name": "sdo-cli",
   "language": "python",
   "name": "sdo-cli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
